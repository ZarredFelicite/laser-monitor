# YOLOE — Ultralytics (extracted)

This file contains an extracted and condensed reference for YOLOE from the Ultralytics documentation (https://docs.ultralytics.com/models/yoloe/). It is intended to be used by developers and agents working on this project so they don't need to fetch the web page repeatedly.

---

## Intro / Summary

YOLOE (Real-Time Seeing Anything) is an open-vocabulary, promptable YOLO-family model providing text, visual, and prompt-free modes for detection and instance segmentation. It introduces RepRTA (text prompt refinement), SAVPE (visual prompt encoder), and LRPC (lazy region-prompt contrast) to enable zero-shot and few-shot detection.

Key points:
- Supports open-vocabulary detection (text and visual prompts).
- Prompt-free variants include a large built-in vocabulary.
- Keeps inference cost identical to closed-set YOLO when prompt modules are re-parameterized.
- Available as segmentation-capable checkpoints (e.g. yoloe-11s-seg.pt, yoloe-11l-seg.pt, yoloe-v8s-seg.pt, etc.).

## Official weights (examples)

- yoloe-11s-seg.pt
- yoloe-11m-seg.pt
- yoloe-11l-seg.pt
- yoloe-v8s-seg.pt
- yoloe-v8m-seg.pt
- yoloe-v8l-seg.pt
- prompt-free variants: yoloe-11s-seg-pf.pt, yoloe-11l-seg-pf.pt, etc.

Official assets are linked from Ultralytics assets releases. Example weight URL format:
https://github.com/ultralytics/assets/releases/download/v8.3.0/{weight-file}.pt

## Usage snippets (Python API)

- Basic load & predict (text prompts):

from ultralytics import YOLOE
model = YOLOE("yoloe-11l-seg.pt")
names = ["person", "bus"]
model.set_classes(names, model.get_text_pe(names))
results = model.predict("path/to/image.jpg")
results[0].show()

- Visual prompts with bounding boxes (intra-image):

import numpy as np
from ultralytics import YOLOE
from ultralytics.models.yolo.yoloe import YOLOEVPSegPredictor

model = YOLOE("yoloe-11l-seg.pt")
visual_prompts = dict(
    bboxes=np.array([[221.52, 405.8, 344.98, 857.54], [120, 425, 160, 445]]),
    cls=np.array([0, 1]),
)
results = model.predict("ultralytics/assets/bus.jpg", visual_prompts=visual_prompts, predictor=YOLOEVPSegPredictor)
results[0].show()

- Visual prompts with separate refer_image (reference example image):

results = model.predict("ultralytics/assets/zidane.jpg", refer_image="ultralytics/assets/bus.jpg", visual_prompts=visual_prompts, predictor=YOLOEVPSegPredictor)

- Prompt-free models (no prompts required):

model = YOLOE("yoloe-11l-seg-pf.pt")
results = model.predict("path/to/image.jpg")
results[0].show()

- Validation & training examples are available in the Ultralytics docs (train usage, val usage, trainer classes like YOLOEPESegTrainer).

## Important API notes / functions referenced in the docs

- YOLOE(...) — construct the model with the path or yaml
- model.predict(...) — wrapper for inference; supports visual_prompts, refer_image, predictor argument
- model.set_classes(names, model.get_text_pe(names)) — set classes using text prompts
- model.get_text_pe(names) — get text prompt embeddings for names
- Predictor classes: YOLOEVPSegPredictor (visual prompt predictor)
- model.train(..., trainer=Trainer) — you might need to pass special Trainer classes (YOLOEPESegTrainer, YOLOEPETrainer)

## References / Links
- Official docs: https://docs.ultralytics.com/models/yoloe/
- Paper: https://arxiv.org/abs/2503.07465
- GitHub YOLOE: https://github.com/THU-MIG/yoloe
- Example weight release URL pattern: https://github.com/ultralytics/assets/releases/download/v8.3.0/{weight-file}.pt

---

This file was autogenerated by an internal agent using the Ultralytics documentation as the source. For the canonical and most up-to-date content consult the official Ultralytics docs and the YOLOE GitHub repo.
